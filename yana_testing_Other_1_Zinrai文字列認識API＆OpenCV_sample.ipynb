{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yana-testing- Other-1_Zinrai文字列認識API＆OpenCV_sample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gh-yana/testing1/blob/master/yana_testing_Other_1_Zinrai%E6%96%87%E5%AD%97%E5%88%97%E8%AA%8D%E8%AD%98API%EF%BC%86OpenCV_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRHwgDPUs-EU",
        "colab_type": "text"
      },
      "source": [
        "### ※※事前準備※※"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-XBDAEXr2fX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZsIPRd4r2Qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Driveアクセス準備\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-W0AxJktZDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Driveからのコピー\n",
        "id = '13ZVJRHcGqgJhW4eKMbz4OHpR7dyh5V2h'  # 共有リンクで取得した id= より後の部分\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('test1.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdNfJoyatgs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#コピーされてるか確認\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulWjjaMEDKmG",
        "colab_type": "text"
      },
      "source": [
        "# Zinrai 手書文字列認識APIの基本的な使い方　<img src=\"https://www.fujitsu.com/jp/imagesgig5/handwritten-text-line-recognition_tcm102-3907272_tcm102-2750236-32.png\" width=\"80\">  \n",
        "[手書文字列認識APIの商品情報はこちら](https://www.fujitsu.com/jp/solutions/business-technology/ai/ai-zinrai/services/platform/handwritten-text-line-recognition/index.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64Y2GN6Kf1z2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6prfRbwQFSMC",
        "colab_type": "text"
      },
      "source": [
        "## はじめに（必要な作業）\n",
        "<font color=\"Red\">Zinrai手書文字列認識は、<b>行単位で切り取られた領域内の手書き画像を文字認識する機能</b>　です。</font>\n",
        "1.   帳票の電子化（スキャナ、カメラなど）\n",
        "2.   認識箇所の切り出し（OCRソフトウェア、OSSで自作など）**※今回はサンプルとしてOpenCV(オープンソース)でコーディング**\n",
        "3.   切り出した画像から文字列をテキスト認識<b><font color=\"Red\">『Zinrai 手書文字列認識API』 ←★ここが Zinrai-API ★</font></b>\n",
        "\n",
        "※OCRソフトウェアにはPFU製の**「[DynaEyeシリーズ](https://www.pfu.fujitsu.com/dynaeye/)」**などがあります（DynaEyeは.NET Frameworkでの開発が可能）。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FreHhBDYf6dQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr4ZhSapH-8s",
        "colab_type": "text"
      },
      "source": [
        "## 認識箇所の切り出し ～OpenCV(オープンソース)＆Pythonでの実装例～\n",
        "\n",
        "OpenCVとは\n",
        "> Open Source Computer Vision Libraryとしてインテルが開発・公開したオープンソースのコンピュータビジョン向けライブラリ。画像処理・画像解析および機械学習等の機能を持つC/C++、Java、Python、MATLAB用ライブラリで、プラットフォームとしてmacOSやFreeBSD等全てのPOSIXに準拠したUnix系OS、Linux、Windows、Android、iOS等をサポートしている。\n",
        "\n",
        "[詳細はこちら(https://opencv.org)](https://opencv.org/)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4zfAtudGau1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#モジュールインポート\n",
        "import cv2 as cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as  pd\n",
        "from IPython.display import Image,display_png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqv6aJIDtc0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.imread(\"/content/test1.png\")    #ファイル読み込み\n",
        "#plt.imshow(img,)   #元画像表示\n",
        "display_png(Image(\"/content/test1.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKJDqeC-bmyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    #グレースケール変換\n",
        "cv2.imwrite(\"/content/out1_gray1.png\", gray)\n",
        "gray2 = cv2.bitwise_not(gray)    #ネガポジ変換\n",
        "cv2.imwrite(\"/content/out2_gray2.png\", gray2)\n",
        "#plt.imshow(gray2)   #ネガポジ変換画像表示\n",
        "#display_png(Image(\"/content/out2_gray2.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR_zUn5iHRCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges = cv2.Canny(gray, 100, 400)    #Canny法(キャニー)によるエッジ検出\n",
        "cv2.imwrite(\"/content/out3_edges.png\", edges)\n",
        "#plt.imshow(edges)    #Canny法によるエッジ検出画像の表示\n",
        "display_png(Image(\"/content/out3_edges.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DABhu89njVTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 特徴検出の関数(HoughLinesP)で直線を検知する（確率的ハフ変換を利用して，2値画像から線分を検出）\n",
        "lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/360, threshold=80, minLineLength=400, maxLineGap=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2NXcftKaQfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 検知した直線の座標をデータフレームに格納する\n",
        "cols = ['x1', 'y1', 'x2', 'y2']\n",
        "df = pd.DataFrame(index=[], columns=cols)\n",
        "for line in lines:\n",
        "    x1, y1, x2, y2 = line[0]\n",
        "    record = pd.Series([x1, y1, x2, y2], index=df.columns)\n",
        "    df = df.append(record, ignore_index=True)\n",
        "#df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgb6fasTvOe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.sort_values(by=['x1','y1'])\n",
        "df = df.reset_index(drop=True)\n",
        "df   # データフレーム（取得した座標データ）の内容を表示する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iivbhtyWQSjv",
        "colab_type": "text"
      },
      "source": [
        "取得した座標から、認識対象領域のみを切り出す（サンプルでは、どの配列を使うかのロジックは実装しておらず、使う配列番号は固定としている。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3siSZBlmTMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 切り取り（例 1）  roi = img[y:y+h, x:x+w]　　x,y:左上座標　w,h:幅高さ\n",
        "x = df.loc[7,\"x1\"]\n",
        "y = df.loc[7,\"y1\"] +3  # +3は線を含ませないための暫定補正\n",
        "w = df.loc[7,\"x2\"] - x\n",
        "h = df.loc[6,\"y2\"] - y\n",
        "\n",
        "img = cv2.imread(\"/content/test1.png\")    #基ファイル読み込み\n",
        "roi = img[y:y+h, x:x+w]   # 領域切り取り\n",
        "#plt.imshow(roi)\n",
        "cv2.imwrite(\"/content/cut1.png\", roi)   # ファイル保存（Zinrai文字列認識で使う画像データ）\n",
        "display_png(Image(\"/content/cut1.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nhz8Cums_QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 切り取り（例 2）  roi = img[y:y+h, x:x+w]　　x,y:左上座標　w,h:幅高さ\n",
        "x = df.loc[5,\"x1\"]\n",
        "y = df.loc[5,\"y1\"] +3  # +3は線を含ませないための暫定補正\n",
        "w = df.loc[5,\"x2\"] - x\n",
        "h = df.loc[4,\"y2\"] - y\n",
        "\n",
        "img = cv2.imread(\"/content/test1.png\")    #基ファイル読み込み\n",
        "roi = img[y:y+h, x:x+w]   # 領域切り取り\n",
        "#plt.imshow(roi)\n",
        "cv2.imwrite(\"/content/cut1.png\", roi)   # ファイル保存（Zinrai文字列認識で使う画像データ）\n",
        "display_png(Image(\"/content/cut1.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UsIPuPOQuty",
        "colab_type": "text"
      },
      "source": [
        "**ここまでが、ZinraiAPIを使うための前処理となる。（認識対象領域の切り出しは、ユーザ開発）**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW3pjXhZ_DML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_MNfnas_C_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxJ2JEuzRLkp",
        "colab_type": "text"
      },
      "source": [
        "## Zinrai APIによる手書き文字列認識 ～Pythonでの実装例～\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFdJffgORn49",
        "colab_type": "text"
      },
      "source": [
        "### APIトークンの取得\n",
        "\n",
        "ZinraiAPIを実行するためのトークン(認証情報)を取得する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7dIlRQs_Cye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests     # ライブラリインポート\n",
        "import json\n",
        "\n",
        "url = \"https://auth-api.jp-east-1.paas.cloud.global.fujitsu.com/API/oauth2/token\"\n",
        "#payload = \"grant_type=client_credentials&scope=service_contract&client_id=aiservetrial080&client_secret=55954ai4-4oss-5ea1-9a55-12754Fad5ai\"   # IDとパスワードを設定\n",
        "payload = \"grant_type=client_credentials&scope=service_contract&client_id=aiservicetrial&client_secret=kR4H,ut9R#Ei4NEADAFcUsT_.U4FdYy*_!CnpnYx\"   # IDとパスワードを設定\n",
        "headers = { \"content-type\": \"application/x-www-form-urlencoded;charset=UTF-8\" }\n",
        "\n",
        "response = requests.request(\"POST\", url, data=payload, headers=headers)    # WebAPIの実行\n",
        "#print(\"API RC:  \",response.status_code)\n",
        "#print(\"レスポンスの全データ:\",response.text)\n",
        "\n",
        "json_dict = json.loads(response.text)      # 戻り値(JSON)をDICT型に変換\n",
        "token = json_dict.get('access_token')      # トークンだけを取り出し\n",
        "print(\"取得したアクセストークン ：  \" ,token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtlJitAVST6_",
        "colab_type": "text"
      },
      "source": [
        "### 文字列認識したい画像データをAPIに渡すための前処理を行う（base64encode）\n",
        "\n",
        "※WebAPI(httpプロトコル)で画像データを送るために、画像データをアスキー文字列に変換する(base64encode)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xguEveZ0lY62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import base64\n",
        "temp0 = open('/content/cut1.png', 'rb').read()    #APIに渡す画像データの読み込み\n",
        "b64str = base64.b64encode( temp0 )   #base64でencode\n",
        "b64str = b64str.decode(\"ascii\")   #バイナリ型からストリング型に変換\n",
        "print(b64str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfcU25H7TO2X",
        "colab_type": "text"
      },
      "source": [
        "### 手書文字列認識を実行する\n",
        "\n",
        "※非同期処理となるため、文字列認識APIを実行して「処理受付ID」を取得する。以降、この処理受付IDを使って、文字認識の結果を取得する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuOezxeW_Ckv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://zinrai-pf.jp-east-1.paas.cloud.global.fujitsu.com/HandwrittenTextLineRecognition/v1/recognitions\"   # URIとモード指定\n",
        "headers = {\n",
        "      \"X-Service-Code\": \"FJAI000016-00001\" ,                  #手書文字列認識モード\n",
        "      \"content-type\": \"application/json;charset=UTF-8\" , \n",
        "      \"X-Access-Token\": \"\" +token+ \"\"                         #アクセストークン設定\n",
        "      }\n",
        "\n",
        "# Bodyデータ  ※encodeImageにbase64encodeした画像データを代入する\n",
        "payload = '{\\\n",
        "  \"singleImage\": {\\\n",
        "    \"recognitionObjects\": [\\\n",
        "      {\\\n",
        "        \"name\": \"image001\",\\\n",
        "        \"lineObject\": {\\\n",
        "          \"encodeImage\": \"' + b64str + '\",\\\n",
        "          \"encodeType\": \"base64string\"\\\n",
        "        },\\\n",
        "        \"option\": {\\\n",
        "          \"characterModel\": \"all\",\\\n",
        "          \"fieldModel\": \"gen_all\",\\\n",
        "          \"correction\": false\\\n",
        "        }\\\n",
        "      }\\\n",
        "    ]\\\n",
        "  }\\\n",
        "}'\n",
        "#print(headers)\n",
        "#print (payload)\n",
        "\n",
        "response = requests.request(\"POST\", url, data=payload, headers=headers)    # WebAPIの実行\n",
        "print(\"API RC:  \",response.status_code)\n",
        "print(\"レスポンス:\",response.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT6Xw0Qb5RU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actid = response.text[11:35]    # 処理受付ID(act_id)を切り取る\n",
        "print(\"処理受付ID:\",actid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNZw10ObUdtD",
        "colab_type": "text"
      },
      "source": [
        "### 文字列認識の「結果(テキスト文字)」を取得する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yc1Zl57_CUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://zinrai-pf.jp-east-1.paas.cloud.global.fujitsu.com/HandwrittenTextLineRecognition/v1/recognitions/\" + actid   # URIとモード指定\n",
        "headers = {\n",
        "      \"X-Service-Code\": \"FJAI000016-00006\" ,                  #結果取り出しモード\n",
        "      \"content-type\": \"application/json;charset=UTF-8\" , \n",
        "      \"X-Asynchronous-CallId\":\"\" +actid+ \"\" ,                 #処理受付ID(Act_id)の設定\n",
        "      \"X-Access-Token\": \"\" +token+ \"\"                         #アクセストークン設定\n",
        "      }\n",
        "#print(headers)\n",
        "#print (payload)\n",
        "\n",
        "response = requests.request(\"GET\", url, data=payload, headers=headers)    # WebAPIの実行\n",
        "print(\"API RC:  \",response.status_code)\n",
        "print(\"レスポンス:\",response.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "839friDwklmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_resp = json.loads(response.text)      # 戻り値(JSON)をDICT型に変換\n",
        "print(json.dumps(json_resp,indent=3,ensure_ascii=False))   #jsonデータの表示"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYwcsuruVBF4",
        "colab_type": "text"
      },
      "source": [
        "＜参考＞文字列認識の基となった画像データ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnkj6F1NvCkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_png(Image(\"/content/cut1.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDG6IvmJvCVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybScp6cejVHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7KtlG01eT9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}